{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "a = torch.rand((50, 10))\n",
    "b = torch.rand((100, 10))\n",
    "\n",
    "c = torch.einsum(\"ij,nj->in\", a , b)\n",
    "\n",
    "(c.view(-1, 1).mm(a.view(1, -1))).shape\n",
    "c.view(-1, 1).shape\n",
    "for i in (a):\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0080, 0.0000, 0.6692, 0.4163, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2300, 0.5042, 0.5466],\n",
      "        [0.0000, 0.2070, 0.0000, 0.3685, 0.0575]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 1, 1],\n",
       "        [0, 1, 0, 1, 1]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((5, 5)) - torch.rand((5, 5))\n",
    "c = a.apply_(lambda x: max(0, x))\n",
    "print(c)\n",
    "z = (c != torch.tensor([0])) \n",
    "torch.tensor([0]) + z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    # Defining __call__ method to keep the easy syntax for the forward prop\n",
    "    def __call__(self, input):\n",
    "        return self.forward(input)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def backward(self, gradwrtoutput):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def params(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class ReLU(Module):\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return input.apply_(lambda x: max(0, x))\n",
    "\n",
    "    def derivative(self,input):\n",
    "        der_bool = (self.forward(input) != torch.tensor([0])) # True if ReLU of x is not zero\n",
    "        return der_bool #+ torch.tensor([0]) # only to give back non-boolean tensor explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0080, 0.0000, 0.6692, 0.4163, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2300, 0.5042, 0.5466],\n",
      "        [0.0000, 0.2070, 0.0000, 0.3685, 0.0575]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False,  True,  True, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False,  True,  True,  True],\n",
       "        [False,  True, False,  True,  True]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu = ReLU()\n",
    "\n",
    "print(relu(a))\n",
    "relu.derivative(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9776258cb6398d27f5227b85aed097ba1d94f1dc0f3390982c9d110f6351e5c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
