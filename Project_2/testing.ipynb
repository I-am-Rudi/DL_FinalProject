{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device for all tensor calculations.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import framework.nn_fw as nn \n",
    "import framework.train_test_fw as tt\n",
    "from visualization import *\n",
    "from tqdm.notebook import tqdm\n",
    "from generate_data import *\n",
    "\n",
    "torch.set_grad_enabled(False)  # explicitly enforces expectation for the task \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using cuda device for all tensor calculations.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using cpu device for all tensor calculations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Data as instructed in task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_disc_set(2_000, split=.5, one_hot_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking wether dataset is created correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential\n",
    "architecture = (nn.Linear(2, 25), nn.Sigmoid(), nn.Linear(25, 25), nn.ReLU(), nn.Linear(25, 1), nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62234f7ce21c42bf985bfaf2a5edc871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1331 / 50000 , Accuracy(Training): (51.700%), Accuracy(Test): (54.800%)\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/rudi/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/testing.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rudi/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/testing.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rudi/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/testing.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rudi/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/testing.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     mean, std \u001b[39m=\u001b[39m tt\u001b[39m.\u001b[39;49mrun_analysis(model, architecture, data, nb_trials, epochs, device, batch_size\u001b[39m=\u001b[39;49mbatch_size, lr \u001b[39m=\u001b[39;49m learning_rate, name \u001b[39m=\u001b[39;49m trial_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rudi/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/testing.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rudi/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/testing.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     logging\u001b[39m.\u001b[39mexception(err)\n",
      "File \u001b[0;32m~/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/framework/train_test_fw.py:109\u001b[0m, in \u001b[0;36mrun_analysis\u001b[0;34m(model, layers, data, nb_trials, epochs, device, name, batch_size, lr, loss, optimizer)\u001b[0m\n\u001b[1;32m    106\u001b[0m test_accuracy \u001b[39m=\u001b[39m []\n\u001b[1;32m    108\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(nb_trials)):\n\u001b[0;32m--> 109\u001b[0m     test_accuracy\u001b[39m.\u001b[39mappend(run_trial(model, layers, data, epochs, device, batch_size, loss, optimizer, lr, name))\n\u001b[1;32m    111\u001b[0m mean \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(torch\u001b[39m.\u001b[39mtensor(test_accuracy), \u001b[39m0\u001b[39m)\n\u001b[1;32m    112\u001b[0m std \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstd(torch\u001b[39m.\u001b[39mtensor(test_accuracy), \u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/framework/train_test_fw.py:86\u001b[0m, in \u001b[0;36mrun_trial\u001b[0;34m(model, layers, data, epochs, device, batch_size, loss, optimizer, lr, name)\u001b[0m\n\u001b[1;32m     83\u001b[0m best_test_accuracy \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m---> 86\u001b[0m     train_accuracy\u001b[39m.\u001b[39mappend(teacher\u001b[39m.\u001b[39;49mtrain(NN, lr))\n\u001b[1;32m     87\u001b[0m     test_l, test_acc \u001b[39m=\u001b[39m teacher\u001b[39m.\u001b[39mtest(NN)\n\u001b[1;32m     88\u001b[0m     test_loss\u001b[39m.\u001b[39mappend(test_l)\n",
      "File \u001b[0;32m~/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/framework/train_test_fw.py:46\u001b[0m, in \u001b[0;36mTeacher.train\u001b[0;34m(self, model, lr)\u001b[0m\n\u001b[1;32m     42\u001b[0m optim\u001b[39m.\u001b[39mto_device(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     44\u001b[0m loss \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSE(targets)\n\u001b[0;32m---> 46\u001b[0m grads \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mbackward(loss)\n\u001b[1;32m     47\u001b[0m model\u001b[39m.\u001b[39mupdate(optim)\n\u001b[1;32m     49\u001b[0m num_errors \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m compute_nb_errors(output, targets)\n",
      "File \u001b[0;32m~/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/framework/nn_fw.py:140\u001b[0m, in \u001b[0;36mSequential.backward\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    138\u001b[0m         grads\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[i]\u001b[39m.\u001b[39mbackward(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], grads[i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], loss \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m))\n\u001b[1;32m    139\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m         grads\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers[i]\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers[i\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], grads[i\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]))\n\u001b[1;32m    143\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    144\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]  \u001b[39m# reformat the layer variable\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/framework/nn_fw.py:71\u001b[0m, in \u001b[0;36mLinear.backward\u001b[0;34m(self, prev_layer, grad)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward\u001b[39m(\u001b[39mself\u001b[39m, prev_layer, grad):\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdb \u001b[39m=\u001b[39m prev_layer\u001b[39m.\u001b[39;49mderivative(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ms) \u001b[39m*\u001b[39m grad\n\u001b[1;32m     72\u001b[0m     \u001b[39m#self.db = torch.einsum(\"ik,jk->ij\", prev_layer.derivative(self.s), grad)\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdw \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\u001b[39m'\u001b[39m\u001b[39mik,ij->ikj\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdb, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx)\n",
      "File \u001b[0;32m~/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/framework/nn_fw.py:244\u001b[0m, in \u001b[0;36mSigmoid.derivative\u001b[0;34m(self, input, activation)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mif\u001b[39;00m activation:\n\u001b[1;32m    242\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mChaining of two activation functions directly after one another!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 244\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39minput\u001b[39m) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39minput\u001b[39;49m))\n",
      "File \u001b[0;32m~/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/framework/nn_fw.py:238\u001b[0m, in \u001b[0;36mSigmoid.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m--> 238\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39m(\u001b[39m1\u001b[39m\u001b[39m+\u001b[39mtorch\u001b[39m.\u001b[39;49mexp(\u001b[39m-\u001b[39;49m\u001b[39minput\u001b[39;49m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trial_name = \"test\"\n",
    "nb_trials = 50\n",
    "epochs = 50_000\n",
    "batch_size = 100\n",
    "learning_rate = 0.0001\n",
    "\n",
    "mean, std = tt.run_analysis(model, architecture, data, nb_trials, epochs, device, batch_size=batch_size, lr = learning_rate, name = trial_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ones_like(): argument 'input' (position 1) must be Tensor, not method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/rudi/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/testing.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rudi/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/testing.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m best_run \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mload_model(\u001b[39m\"\u001b[39m\u001b[39mbest_model_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m trial_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_epochs_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epochs))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rudi/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/testing.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m output \u001b[39m=\u001b[39m best_run(data[\u001b[39m2\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rudi/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/testing.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m errors \u001b[39m=\u001b[39m tt\u001b[39m.\u001b[39;49mcompute_nb_errors(output, data[\u001b[39m3\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rudi/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/testing.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m accuracy \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m errors\u001b[39m/\u001b[39m(data[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rudi/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/testing.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe best performing model from the previous analysis achieves: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Uni/Courses-Exchange/DeepLearning/Final_Project/Project_2/framework/train_test_fw.py:19\u001b[0m, in \u001b[0;36mcompute_nb_errors\u001b[0;34m(pred, target, one_hot_labels)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mround(pred)\n\u001b[0;32m---> 19\u001b[0m     pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmin(pred, torch\u001b[39m.\u001b[39;49mones_like(\u001b[39minput\u001b[39;49m))\n\u001b[1;32m     20\u001b[0m     wrong \u001b[39m=\u001b[39m (pred \u001b[39m!=\u001b[39m target)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     21\u001b[0m \u001b[39mreturn\u001b[39;00m wrong\n",
      "\u001b[0;31mTypeError\u001b[0m: ones_like(): argument 'input' (position 1) must be Tensor, not method"
     ]
    }
   ],
   "source": [
    "best_run = nn.load_model(\"best_model_\" + trial_name + '_epochs_{}'.format(epochs))\n",
    "output = best_run(data[2])\n",
    "errors = tt.compute_nb_errors(output, data[3])\n",
    "accuracy = 1 - errors/(data[2].shape[0])\n",
    "\n",
    "print(\"The best performing model from the previous analysis achieves: \\n\")\n",
    "print(\"Test accuracy: ({:.3f}%)\".format(100. * accuracy), \"   |     Total number of errors {}\".format(errors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9776258cb6398d27f5227b85aed097ba1d94f1dc0f3390982c9d110f6351e5c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
